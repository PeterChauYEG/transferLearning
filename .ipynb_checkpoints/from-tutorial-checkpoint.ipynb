{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning based on online tutorials\n",
    "This notebook explores transfer learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import backend as k\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "import os\n",
    "\n",
    "from IPython.display import SVG\n",
    "import pydot\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_modelz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "# inline matplotlib's graphs\n",
    "%matplotlib inline\n",
    "\n",
    "# to use GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "input_channels = 3\n",
    "input_height, input_width = 256, 256\n",
    "\n",
    "# data\n",
    "data_train_dir = 'images/train/'\n",
    "data_validation_dir = 'images/validation/'\n",
    "n_classes = 4\n",
    "n_train = 20\n",
    "n_validation = 10\n",
    "\n",
    "# output\n",
    "output_checkpoint_dir = 'checkpoint/from-tutorial-1.h5'\n",
    "output_diagram_dir = 'diagram/from-tutorial-1.png'\n",
    "output_logs_dir = 'logs/'\n",
    "\n",
    "# hyperparameters\n",
    "batch_size = 5\n",
    "freeze_layers = None\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Generators\n",
    "The images should be stored in the following directory structure:  \n",
    "images:  \n",
    "   - test:  \n",
    "       - category_0:  \n",
    "       - category_1:  \n",
    "       - category_2:  \n",
    "       - category_3:  \n",
    "   - validation:  \n",
    "       - category_0:  \n",
    "       - category_1:  \n",
    "       - category_2:  \n",
    "       - category_3:        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data generators\n",
    "train_datagen = ImageDataGenerator()\n",
    "\n",
    "validation_datagen = ImageDataGenerator()\n",
    "\n",
    "# initialize them\n",
    "train_generator = train_datagen.flow_from_directory(data_train_dir,\n",
    "                                                    target_size=(input_height, input_width),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(data_validation_dir,\n",
    "                                                              target_size=(input_height, input_width),\n",
    "                                                              class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the VGG19 network with it's pretrained weights\n",
    "# include_top refers to the fully connected layers. We don't need this part because we will add our own\n",
    "# we need to specify the shape of our inputs\n",
    "model = applications.VGG19(weights='imagenet',\n",
    "                           include_top=False,\n",
    "                           input_shape=(input_width, input_height, input_channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the loaded model\n",
    "# we should see that the loaded model has the FC layers + softmax removed\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers we don't want to train. To start, lets freeze all of them... just to see if this works.\n",
    "for layer in model.layers[:freeze_layers]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the layers and check that they are frozen correctly\n",
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build our custom layers\n",
    "# take the output of the loaded model (some x, some y, some c)\n",
    "x = model.output \n",
    "\n",
    "# flatten it so that we can feed it to fully connected layers\n",
    "x = Flatten(name='flatten')(x)\n",
    "\n",
    "# feed into a fc layer with a relu activation and output 1024 units\n",
    "x = Dense(1024, activation='relu', name='fc_1')(x)\n",
    "\n",
    "# use dropout for a normalizing effect\n",
    "x = Dropout(0.5, name='do_1')(x)\n",
    "\n",
    "# feed into a fc layer with a relu activation and output 1024 units\n",
    "x = Dense(1024, activation='relu', name='fc_2')(x)\n",
    "\n",
    "# feed into a softmax to make final predictions of n_classes\n",
    "predictions = Dense(n_classes, activation='softmax', name='prediction')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model\n",
    "model = Model(input=model.input, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=0.0001, momentum=0.9), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine our model with our custom layers.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw a diagram of the model and save it disk\n",
    "plot_model(model, to_file=output_diagram_dir)\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and use early stopping\n",
    "checkpoint = ModelCheckpoint(output_checkpoint_dir, \n",
    "                             monitor='val_acc', \n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             save_weights_only=False,\n",
    "                             mode='auto',\n",
    "                             period=1)\n",
    "\n",
    "early = EarlyStopping(monitor='val_acc', \n",
    "                      min_delta=0,\n",
    "                      patience=10,\n",
    "                      verbose=1,\n",
    "                      mode='auto')\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=output_logs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=n_train/batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=n_validation,\n",
    "                    callbacks=[checkpoint, early, tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[Transfer Learning using Keras](https://medium.com/@14prakash/transfer-learning-using-keras-d804b2e04ef8)\n",
    "[Keras Tutorial: Fine-tuning using pre-trained models](https://www.learnopencv.com/keras-tutorial-fine-tuning-using-pre-trained-models/)\n",
    "[keras](https://keras.io)\n",
    "[deeplearning.ai](https://www.deeplearning.ai/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
